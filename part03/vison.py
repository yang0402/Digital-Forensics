import json
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import Rectangle
import seaborn as sns
import pandas as pd
import numpy as np
from datetime import datetime
import os
from typing import Dict, List
import warnings
warnings.filterwarnings('ignore')

# ä¿®å¤ä¸­æ–‡å­—ä½“æ˜¾ç¤ºé—®é¢˜
def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ"""
    import matplotlib.font_manager as fm
    
    # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
    chinese_fonts = [
        'SimHei',           # é»‘ä½“ (Windows)
        'Microsoft YaHei',  # å¾®è½¯é›…é»‘ (Windows)
        'PingFang SC',      # è‹¹æ–¹ (macOS)
        'Hiragino Sans GB', # å†¬é’é»‘ä½“ (macOS)
        'WenQuanYi Micro Hei', # æ–‡æ³‰é©¿å¾®ç±³é»‘ (Linux)
        'Noto Sans CJK SC', # æ€æºé»‘ä½“ (Linux)
        'DejaVu Sans'       # å¤‡ç”¨å­—ä½“
    ]
    
    # è·å–ç³»ç»Ÿå¯ç”¨å­—ä½“
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
    selected_font = 'DejaVu Sans'  # é»˜è®¤å­—ä½“
    for font in chinese_fonts:
        if font in available_fonts:
            selected_font = font
            break
    
    print(f"ğŸ“ ä½¿ç”¨å­—ä½“: {selected_font}")
    
    # è®¾ç½®matplotlibå­—ä½“
    plt.rcParams['font.sans-serif'] = [selected_font, 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['font.size'] = 10
    
    return selected_font

class AnalysisVisualizer:
    """è¯­ä¹‰åˆ†æç»“æœå¯è§†åŒ–å·¥å…·"""
    
    def __init__(self, json_file: str):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
        Args:
            json_file: JSONæ–‡ä»¶è·¯å¾„
        """
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        self.font_name = setup_chinese_fonts()
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½JSONæ–‡ä»¶: {json_file}")
        except FileNotFoundError:
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {json_file}")
        except json.JSONDecodeError as e:
            raise ValueError(f"âŒ JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
        except Exception as e:
            raise Exception(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        
        # è®¾ç½®é¢œè‰²ä¸»é¢˜
        self.colors = {
            'High Risk': '#FF4444',      # é«˜é£é™©
            'Medium Risk': '#FF8800',    # ä¸­é£é™©
            'Low Risk': '#FFCC00',       # ä½é£é™©
            'No Risk': '#44AA44',        # æ— é£é™©
            'Error': '#888888',          # é”™è¯¯
            'Unknown': '#CCCCCC',        # æœªçŸ¥
            # ä¸­æ–‡æ˜ å°„
            'é«˜é£é™©': '#FF4444',
            'ä¸­é£é™©': '#FF8800', 
            'ä½é£é™©': '#FFCC00',
            'æ— é£é™©': '#44AA44',
            'é”™è¯¯': '#888888',
            'æœªçŸ¥': '#CCCCCC'
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = "visualization_output"
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_dir}")

    def create_dashboard(self, save_path: str = None) -> str:
        """åˆ›å»ºç»¼åˆä»ªè¡¨æ¿"""
        if save_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            save_path = os.path.join(self.output_dir, f"analysis_dashboard_{timestamp}.png")
        
        # åˆ›å»ºå¤§å›¾å¸ƒå±€ (3è¡Œ4åˆ—)
        fig = plt.figure(figsize=(20, 15))
        
        # ä½¿ç”¨è‹±æ–‡æ ‡é¢˜é¿å…å­—ä½“é—®é¢˜
        fig.suptitle('Semantic Analysis Dashboard / è¯­ä¹‰åˆ†æç»“æœä»ªè¡¨æ¿', 
                    fontsize=20, fontweight='bold', y=0.95)
        
        # 1. é£é™©ç­‰çº§åˆ†å¸ƒé¥¼å›¾
        ax1 = plt.subplot(3, 4, 1)
        self._plot_risk_distribution_pie(ax1)
        
        # 2. é£é™©ç­‰çº§åˆ†å¸ƒæŸ±çŠ¶å›¾
        ax2 = plt.subplot(3, 4, 2)
        self._plot_risk_distribution_bar(ax2)
        
        # 3. ç½®ä¿¡åº¦åˆ†å¸ƒ
        ax3 = plt.subplot(3, 4, 3)
        self._plot_confidence_distribution(ax3)
        
        # 4. æ•æ„Ÿè¯ç±»åˆ«ç»Ÿè®¡
        ax4 = plt.subplot(3, 4, 4)
        self._plot_sensitive_word_categories(ax4)
        
        # 5. æ–‡æœ¬é£é™©çƒ­åŠ›å›¾
        ax5 = plt.subplot(3, 4, (5, 6))
        self._plot_text_risk_heatmap(ax5)
        
        # 6. æ•æ„Ÿè¯æ•°é‡åˆ†å¸ƒ
        ax6 = plt.subplot(3, 4, 7)
        self._plot_sensitive_word_count(ax6)
        
        # 7. è¯­ä¹‰æ¨¡å¼ç»Ÿè®¡
        ax7 = plt.subplot(3, 4, 8)
        self._plot_semantic_patterns(ax7)
        
        # 8. è¯¦ç»†æ–‡æœ¬åˆ†æ (å ç”¨åº•éƒ¨å¤§ç©ºé—´)
        ax8 = plt.subplot(3, 1, 3)
        self._plot_detailed_text_analysis(ax8)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.92, hspace=0.3, wspace=0.3)
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"ğŸ“Š ä»ªè¡¨æ¿å·²ä¿å­˜åˆ°: {save_path}")
        return save_path

    def _plot_risk_distribution_pie(self, ax):
        """ç»˜åˆ¶é£é™©ç­‰çº§åˆ†å¸ƒé¥¼å›¾"""
        risk_dist = self.data['summary_statistics']['risk_level_distribution']
        
        # è½¬æ¢ä¸ºè‹±æ–‡æ ‡ç­¾
        label_mapping = {
            'é«˜é£é™©': 'High Risk',
            'ä¸­é£é™©': 'Medium Risk', 
            'ä½é£é™©': 'Low Risk',
            'æ— é£é™©': 'No Risk',
            'é”™è¯¯': 'Error'
        }
        
        labels = []
        sizes = []
        colors = []
        
        for chinese_label, count in risk_dist.items():
            english_label = label_mapping.get(chinese_label, chinese_label)
            labels.append(f"{english_label}\n({chinese_label})")
            sizes.append(count)
            colors.append(self.colors.get(chinese_label, '#CCCCCC'))
        
        wedges, texts, autotexts = ax.pie(sizes, labels=labels, colors=colors, 
                                         autopct='%1.1f%%', startangle=90,
                                         textprops={'fontsize': 9})
        ax.set_title('Risk Level Distribution', fontsize=12, fontweight='bold')
        
        # ç¾åŒ–æ–‡æœ¬
        for autotext in autotexts:
            autotext.set_color('white')
            autotext.set_fontweight('bold')
            autotext.set_fontsize(8)

    def _plot_risk_distribution_bar(self, ax):
        """ç»˜åˆ¶é£é™©ç­‰çº§åˆ†å¸ƒæŸ±çŠ¶å›¾"""
        risk_dist = self.data['summary_statistics']['risk_level_distribution']
        
        # è½¬æ¢æ ‡ç­¾
        label_mapping = {
            'é«˜é£é™©': 'High\nRisk',
            'ä¸­é£é™©': 'Medium\nRisk', 
            'ä½é£é™©': 'Low\nRisk',
            'æ— é£é™©': 'No\nRisk',
            'é”™è¯¯': 'Error'
        }
        
        labels = []
        values = []
        colors = []
        
        for chinese_label, count in risk_dist.items():
            english_label = label_mapping.get(chinese_label, chinese_label)
            labels.append(english_label)
            values.append(count)
            colors.append(self.colors.get(chinese_label, '#CCCCCC'))
        
        bars = ax.bar(labels, values, color=colors, alpha=0.8, 
                     edgecolor='black', linewidth=1)
        ax.set_title('Risk Level Statistics', fontsize=12, fontweight='bold')
        ax.set_ylabel('Count')
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                   f'{int(height)}', ha='center', va='bottom', fontweight='bold')
        
        if values:
            ax.set_ylim(0, max(values) * 1.2)

    def _plot_confidence_distribution(self, ax):
        """ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        results = self.data['detailed_results']
        confidences = [r.get('confidence_score', 0) for r in results 
                      if r.get('confidence_score', 0) > 0]
        
        if confidences:
            ax.hist(confidences, bins=10, alpha=0.7, color='skyblue', 
                   edgecolor='black', linewidth=1)
            ax.axvline(np.mean(confidences), color='red', linestyle='--', 
                      linewidth=2, label=f'Mean: {np.mean(confidences):.2f}')
            ax.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')
            ax.set_xlabel('Confidence Score')
            ax.set_ylabel('Frequency')
            ax.legend()
        else:
            ax.text(0.5, 0.5, 'No Valid Confidence Data', ha='center', va='center', 
                   transform=ax.transAxes, fontsize=12)
            ax.set_title('Confidence Score Distribution', fontsize=12, fontweight='bold')

    def _plot_sensitive_word_categories(self, ax):
        """ç»˜åˆ¶æ•æ„Ÿè¯ç±»åˆ«ç»Ÿè®¡"""
        categories = self.data['summary_statistics']['sensitive_word_categories']
        
        if categories:
            # é™åˆ¶æ˜¾ç¤ºçš„ç±»åˆ«æ•°é‡ï¼Œé¿å…æ ‡ç­¾é‡å 
            sorted_categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)
            top_categories = sorted_categories[:8]  # åªæ˜¾ç¤ºå‰8ä¸ªç±»åˆ«
            
            labels = [item[0] for item in top_categories]
            values = [item[1] for item in top_categories]
            
            # ä½¿ç”¨ä¸åŒé¢œè‰²
            colors = plt.cm.Set3(np.linspace(0, 1, len(labels)))
            
            bars = ax.barh(labels, values, color=colors, alpha=0.8, 
                          edgecolor='black', linewidth=1)
            ax.set_title('Sensitive Word Categories', fontsize=12, fontweight='bold')
            ax.set_xlabel('Count')
            
            # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
            for i, bar in enumerate(bars):
                width = bar.get_width()
                ax.text(width + 0.1, bar.get_y() + bar.get_height()/2.,
                       f'{int(width)}', ha='left', va='center', fontweight='bold')
            
            # è°ƒæ•´æ ‡ç­¾å­—ä½“å¤§å°
            ax.tick_params(axis='y', labelsize=8)
        else:
            ax.text(0.5, 0.5, 'No Sensitive Word Data', ha='center', va='center', 
                   transform=ax.transAxes, fontsize=12)
            ax.set_title('Sensitive Word Categories', fontsize=12, fontweight='bold')

    def _plot_text_risk_heatmap(self, ax):
        """ç»˜åˆ¶æ–‡æœ¬é£é™©çƒ­åŠ›å›¾"""
        results = self.data['detailed_results']
        
        # åˆ›å»ºæ•°æ®çŸ©é˜µ
        risk_values = {'æ— é£é™©': 0, 'ä½é£é™©': 1, 'ä¸­é£é™©': 2, 'é«˜é£é™©': 3, 'é”™è¯¯': -1}
        
        # å‡†å¤‡æ•°æ®
        text_risks = []
        text_labels = []
        
        for i, result in enumerate(results):
            risk = result.get('risk_level', 'æœªçŸ¥')
            confidence = result.get('confidence_score', 0)
            text_risks.append([risk_values.get(risk, -1), confidence])
            text_labels.append(f'Text{i+1}')
        
        if text_risks:
            data_matrix = np.array(text_risks).T
            
            # åˆ›å»ºçƒ­åŠ›å›¾
            im = ax.imshow(data_matrix, cmap='RdYlGn_r', aspect='auto')
            
            # è®¾ç½®æ ‡ç­¾
            ax.set_xticks(range(len(text_labels)))
            ax.set_xticklabels(text_labels, rotation=45, fontsize=8)
            ax.set_yticks([0, 1])
            ax.set_yticklabels(['Risk Level', 'Confidence'], fontsize=10)
            ax.set_title('Text Risk Heatmap', fontsize=12, fontweight='bold')
            
            # æ·»åŠ æ–‡æœ¬æ³¨é‡Š
            risk_labels = {0: 'Safe', 1: 'Low', 2: 'Med', 3: 'High', -1: 'Err'}
            for i in range(len(text_labels)):
                risk_level = data_matrix[0, i]
                risk_text = risk_labels.get(risk_level, 'Unk')
                ax.text(i, 0, risk_text, ha='center', va='center', 
                       fontsize=8, fontweight='bold')
                ax.text(i, 1, f'{data_matrix[1, i]:.2f}', ha='center', va='center', 
                       fontsize=8, fontweight='bold')

    def _plot_sensitive_word_count(self, ax):
        """ç»˜åˆ¶æ¯ä¸ªæ–‡æœ¬çš„æ•æ„Ÿè¯æ•°é‡"""
        results = self.data['detailed_results']
        
        text_indices = []
        word_counts = []
        colors_list = []
        
        for i, result in enumerate(results):
            text_indices.append(f"Text{i+1}")
            word_counts.append(len(result.get('sensitive_words', [])))
            risk_level = result.get('risk_level', 'æœªçŸ¥')
            colors_list.append(self.colors.get(risk_level, '#CCCCCC'))
        
        bars = ax.bar(text_indices, word_counts, color=colors_list, alpha=0.8, 
                     edgecolor='black', linewidth=1)
        ax.set_title('Sensitive Words per Text', fontsize=12, fontweight='bold')
        ax.set_ylabel('Count')
        ax.tick_params(axis='x', rotation=45, labelsize=8)
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                       f'{int(height)}', ha='center', va='bottom', fontweight='bold')

    def _plot_semantic_patterns(self, ax):
        """ç»˜åˆ¶è¯­ä¹‰æ¨¡å¼ç»Ÿè®¡"""
        results = self.data['detailed_results']
        
        text_indices = []
        pattern_counts = []
        colors_list = []
        
        for i, result in enumerate(results):
            text_indices.append(f"Text{i+1}")
            pattern_counts.append(len(result.get('semantic_patterns', [])))
            risk_level = result.get('risk_level', 'æœªçŸ¥')
            colors_list.append(self.colors.get(risk_level, '#CCCCCC'))
        
        bars = ax.bar(text_indices, pattern_counts, color=colors_list, alpha=0.8, 
                     edgecolor='black', linewidth=1)
        ax.set_title('Semantic Patterns per Text', fontsize=12, fontweight='bold')
        ax.set_ylabel('Count')
        ax.tick_params(axis='x', rotation=45, labelsize=8)
        
        # åœ¨æŸ±å­ä¸Šæ˜¾ç¤ºæ•°å€¼
        for bar in bars:
            height = bar.get_height()
            if height > 0:
                ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,
                       f'{int(height)}', ha='center', va='bottom', fontweight='bold')

    def _plot_detailed_text_analysis(self, ax):
        """ç»˜åˆ¶è¯¦ç»†æ–‡æœ¬åˆ†æ"""
        results = self.data['detailed_results']
        
        # æ¸…é™¤åæ ‡è½´
        ax.set_xlim(0, 10)
        ax.set_ylim(0, len(results))
        ax.axis('off')
        ax.set_title('Detailed Text Analysis', fontsize=14, fontweight='bold', pad=20)
        
        # é£é™©ç­‰çº§æ˜ å°„
        risk_mapping = {
            'é«˜é£é™©': 'High Risk',
            'ä¸­é£é™©': 'Medium Risk',
            'ä½é£é™©': 'Low Risk',
            'æ— é£é™©': 'No Risk',
            'é”™è¯¯': 'Error'
        }
        
        for i, result in enumerate(results):
            y_pos = len(results) - i - 1
            
            # æ–‡æœ¬èƒŒæ™¯è‰²
            risk_level = result.get('risk_level', 'æœªçŸ¥')
            bg_color = self.colors.get(risk_level, '#CCCCCC')
            
            # ç»˜åˆ¶èƒŒæ™¯çŸ©å½¢
            rect = Rectangle((0, y_pos - 0.4), 10, 0.8, 
                            facecolor=bg_color, alpha=0.3, edgecolor='black')
            ax.add_patch(rect)
            
            # æ–‡æœ¬ä¿¡æ¯
            text_content = result.get('original_text', 'N/A')
            if len(text_content) > 60:
                text_content = text_content[:60] + '...'
            
            confidence = result.get('confidence_score', 0)
            sensitive_count = len(result.get('sensitive_words', []))
            risk_english = risk_mapping.get(risk_level, risk_level)
            
            # æ˜¾ç¤ºä¿¡æ¯ï¼ˆä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜ï¼‰
            info_text = f"Text {i+1}: {text_content}\n"
            info_text += f"Risk: {risk_english} | Confidence: {confidence:.2f} | "
            info_text += f"Sensitive Words: {sensitive_count}"
            
            ax.text(0.1, y_pos, info_text, fontsize=9, va='center', 
                   bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.8))

    def create_risk_summary_chart(self, save_path: str = None) -> str:
        """åˆ›å»ºé£é™©æ‘˜è¦å›¾è¡¨"""
        if save_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            save_path = os.path.join(self.output_dir, f"risk_summary_{timestamp}.png")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Risk Analysis Summary', fontsize=18, fontweight='bold')
        
        # 1. é£é™©ç­‰çº§é¥¼å›¾
        self._plot_risk_distribution_pie(ax1)
        
        # 2. ç½®ä¿¡åº¦ç®±çº¿å›¾
        results = self.data['detailed_results']
        risk_confidence = {}
        risk_mapping = {
            'é«˜é£é™©': 'High Risk',
            'ä¸­é£é™©': 'Medium Risk',
            'ä½é£é™©': 'Low Risk',
            'æ— é£é™©': 'No Risk',
            'é”™è¯¯': 'Error'
        }
        
        for result in results:
            risk = result.get('risk_level', 'æœªçŸ¥')
            conf = result.get('confidence_score', 0)
            if conf > 0:
                risk_english = risk_mapping.get(risk, risk)
                if risk_english not in risk_confidence:
                    risk_confidence[risk_english] = []
                risk_confidence[risk_english].append(conf)
        
        if risk_confidence:
            risks = list(risk_confidence.keys())
            confs = [risk_confidence[risk] for risk in risks]
            colors = [self.colors.get(risk, '#CCCCCC') for risk in risks]
            
            bp = ax2.boxplot(confs, labels=risks, patch_artist=True)
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            ax2.set_title('Confidence Distribution by Risk Level', fontsize=12, fontweight='bold')
            ax2.set_ylabel('Confidence Score')
            ax2.tick_params(axis='x', labelsize=8)
        
        # 3. æ•æ„Ÿè¯ç±»åˆ«
        self._plot_sensitive_word_categories(ax3)
        
        # 4. ç»Ÿè®¡æ‘˜è¦
        risk_dist = self.data['summary_statistics']['risk_level_distribution']
        total_texts = sum(risk_dist.values())
        
        ax4.text(0.1, 0.9, f"Total Texts: {total_texts}", transform=ax4.transAxes, 
                 fontsize=12, fontweight='bold')
        ax4.text(0.1, 0.8, f"High Risk: {risk_dist.get('é«˜é£é™©', 0)}", 
                 transform=ax4.transAxes, fontsize=11, color='red')
        ax4.text(0.1, 0.7, f"Medium Risk: {risk_dist.get('ä¸­é£é™©', 0)}", 
                 transform=ax4.transAxes, fontsize=11, color='orange')
        ax4.text(0.1, 0.6, f"Low Risk: {risk_dist.get('ä½é£é™©', 0)}", 
                 transform=ax4.transAxes, fontsize=11, color='gold')
        ax4.text(0.1, 0.5, f"No Risk: {risk_dist.get('æ— é£é™©', 0)}", 
                 transform=ax4.transAxes, fontsize=11, color='green')
        
        avg_conf = self.data['summary_statistics']['average_confidence']
        total_words = self.data['summary_statistics']['total_sensitive_words']
        
        ax4.text(0.1, 0.3, f"Avg Confidence: {avg_conf:.3f}", 
                 transform=ax4.transAxes, fontsize=11)
        ax4.text(0.1, 0.2, f"Total Sensitive Words: {total_words}", 
                 transform=ax4.transAxes, fontsize=11)
        ax4.text(0.1, 0.1, f"Semantic Patterns: {self.data['summary_statistics']['semantic_patterns_count']}", 
                 transform=ax4.transAxes, fontsize=11)
        
        ax4.set_title('Statistics Summary', fontsize=12, fontweight='bold')
        ax4.axis('off')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"ğŸ“ˆ é£é™©æ‘˜è¦å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        return save_path

    def create_all_visualizations(self) -> List[str]:
        """åˆ›å»ºæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        saved_files = []
        
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # 1. ç»¼åˆä»ªè¡¨æ¿
        dashboard_path = self.create_dashboard()
        saved_files.append(dashboard_path)
        
        # 2. é£é™©æ‘˜è¦
        summary_path = self.create_risk_summary_chart()
        saved_files.append(summary_path)
        
        print(f"âœ… æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {self.output_dir}/")
        
        return saved_files

    def print_file_info(self):
        """æ‰“å°æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
        print("\nğŸ“„ File Information:")
        print(f"  Generated: {self.data['analysis_info']['generated_at']}")
        print(f"  Total Texts: {self.data['analysis_info']['total_texts']}")
        print(f"  Analyzer Version: {self.data['analysis_info']['analyzer_version']}")
        print(f"  API Model: {self.data['analysis_info']['api_model']}")
        
        print("\nğŸ“Š Statistics Summary:")
        stats = self.data['summary_statistics']
        print(f"  High Risk Texts: {stats['high_risk_count']}")
        print(f"  Average Confidence: {stats['average_confidence']:.3f}")
        print(f"  Total Sensitive Words: {stats['total_sensitive_words']}")
        print(f"  Semantic Patterns: {stats['semantic_patterns_count']}")
        
        print("\nğŸš¨ Risk Distribution:")
        risk_mapping = {
            'é«˜é£é™©': 'High Risk',
            'ä¸­é£é™©': 'Medium Risk',
            'ä½é£é™©': 'Low Risk',
            'æ— é£é™©': 'No Risk',
            'é”™è¯¯': 'Error'
        }
        for risk, count in stats['risk_level_distribution'].items():
            english_risk = risk_mapping.get(risk, risk)
            print(f"  {english_risk}: {count}")


# ä½¿ç”¨ç¤ºä¾‹
def main():
    # æŒ‡å®šJSONæ–‡ä»¶è·¯å¾„
    json_file_path = "/home/user1/tengyang/forensic_analyzer/part03/analysis_results/semantic_analysis_results_20250617_013417.json"
    
    try:
        print("ğŸ” å¼€å§‹å¤„ç†è¯­ä¹‰åˆ†æç»“æœ...")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = AnalysisVisualizer(json_file_path)
        
        # æ‰“å°æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        visualizer.print_file_info()
        
        # ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
        saved_files = visualizer.create_all_visualizations()
        
        print("\nğŸ‰ å¯è§†åŒ–å®Œæˆ!")
        print("Generated Files:")
        for file in saved_files:
            print(f"  ğŸ“Š {file}")
        
        # æ˜¾ç¤ºå½“å‰å·¥ä½œç›®å½•ä¸‹çš„å¯è§†åŒ–æ–‡ä»¶
        current_dir = os.getcwd()
        vis_dir = os.path.join(current_dir, "visualization_output")
        if os.path.exists(vis_dir):
            print(f"\nğŸ“ Visualization files saved in: {vis_dir}")
            files = os.listdir(vis_dir)
            if files:
                print("  Files:")
                for file in files:
                    print(f"    - {file}")
            
    except FileNotFoundError:
        print(f"âŒ Error: Cannot find the specified JSON file")
        print(f"Please check if the file path is correct: {json_file_path}")
    except Exception as e:
        print(f"âŒ Error during processing: {str(e)}")
        print("Please check file format and content")


if __name__ == "__main__":
    main()